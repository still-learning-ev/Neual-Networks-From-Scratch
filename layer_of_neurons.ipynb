{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer of Neurons\n",
    "### We have seen how to create a single neuron from scratch in the previous chapter in this chapter we are going to see how we can create a layer of neurons.\n",
    "Let us recall what a neuron does from previous chapter\n",
    "1. Neouron takes $n$ number of inputs.\n",
    "2. Mutiplies them with $n$ number of weights one weight for each input.\n",
    "3. Adds a single bias at the end to produce a single valued output.\n",
    "Key points to remember are:\n",
    "- A neuron has as same number of weights as the number of inputs for instance a neuron has 10 inputs will also have 10 weights.\n",
    "- No matter how many inputs are given to a neuron it only has a single bias value (sometimes we don't use bias value hence neuron can also have no bias value).\n",
    "- No matter how many inputs are given to a neuron and if bias is given or not neuron produces a single valued output (scalar value).\n",
    "### What is meant by a layer of neurons or simply a layer.\n",
    "Putting it in simple terms if we bring one or more neurons together and arrange them to be in such a way that the input is acted upon be each single neuron independently and parallely is called layer or layer of neurons. Let us understand it more by an example say we have a single input $x_{0}$ and we have a single neuron say $n_{0}$ we give the neuron input $x_{0}$ and it produces a single output $y_{0}$. Now say that instead of a single neuron we have three neurons $n_{0}\\space n_{1} \\space n_{2}$ and we have the single input $x_{0}$ and we give it to each neuron seprately such that each neuron produces an output $y_{0}\\space y_{1} \\space y_{2}$ such that $n_{0}$ produces output $y_{0}$, $n_{1}$ produces output $y_{1}$ and $n_{2}$ produces output $y_{2}$. This arrangement in which we give input to each and every neuron independently to produce ouputs forms a layer.\n",
    "#### The following example shows the layer of neurons is python:\n",
    "- We have 4 inputs to our neuron $\\textit{i.e}$ n = 4\n",
    "- We have 3 neurons in a single layer and each neuron has a set of weigths of size 4 because input has size 4.\n",
    "- We have 3 biases because we have 3 neurons and each neuron has only one bias so, 3 biases for 3 neurons.\n",
    "- We then do some neuron maths to get output and we have three outputs because we have three neurons and one output per neuron gives us three outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs from layer = [4.8, 1.21, 2.385]\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "Output for Neuron 1 is $y_1$ = 4.8"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Output for Neuron 2 is $y_2$ = 1.21"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Output for Neuron 3 is $y_3$ = 2.385"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For nice printing\n",
    "from IPython.display import display, Latex\n",
    "\n",
    "# inputs\n",
    "inputs = [1, 2, 3, 2.5]\n",
    "\n",
    "# weights for 1st neuron\n",
    "weights1 = [0.2, 0.8, -0.5, 1]\n",
    "\n",
    "# weights for 2nd neuron\n",
    "weights2 = [0.5, -0.91, 0.26, -0.5]\n",
    "\n",
    "# weights for 3rd neuron\n",
    "weights3 = [-0.26, -0.27, 0.17, 0.87]\n",
    "\n",
    "# bias for 1st, 2nd and 3rd neuron\n",
    "bias1 = 2\n",
    "bias2 = 3\n",
    "bias3 = 0.5\n",
    "\n",
    "outputs = [\n",
    "# Neuron 1:\n",
    "inputs[0]*weights1[0] +\n",
    "inputs[1]*weights1[1] +\n",
    "inputs[2]*weights1[2] +\n",
    "inputs[3]*weights1[3] + bias1,\n",
    "\n",
    "# Neuron 2:\n",
    "inputs[0]*weights2[0] +\n",
    "inputs[1]*weights2[1] +\n",
    "inputs[2]*weights2[2] +\n",
    "inputs[3]*weights2[3] + bias2,\n",
    "\n",
    "# Neuron 3:\n",
    "inputs[0]*weights3[0] +\n",
    "inputs[1]*weights3[1] +\n",
    "inputs[2]*weights3[2] +\n",
    "inputs[3]*weights3[3] + bias3]\n",
    "\n",
    "print(f\"Outputs from layer = {outputs}\")\n",
    "\n",
    "for i, op in enumerate(outputs, 1):\n",
    "    out = f\"Output for Neuron {i} is $y_{i}$ = {op}\"\n",
    "    display(Latex(out))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above example a layer produces as many inputs as the number of neurons present in it for instance if a layer has 10 neurons the number of outputs from the layer will be 10.\n",
    "#### We will now make the same layer of neurons using numpy and see how much our life becomes easier by writing small number of lines by using matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs from layer = [4.8, 1.21, 2.385]\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "Output for Neuron 1 is $y_1$ = 4.8"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Output for Neuron 2 is $y_2$ = 1.21"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Output for Neuron 3 is $y_3$ = 2.385"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# inputs\n",
    "inputs = np.array([1, 2, 3, 2.5])\n",
    "\n",
    "# weights for 1st neuron\n",
    "weights1 = np.array([0.2, 0.8, -0.5, 1])\n",
    "\n",
    "# weights for 2nd neuron\n",
    "weights2 = np.array([0.5, -0.91, 0.26, -0.5])\n",
    "\n",
    "# weights for 3rd neuron\n",
    "weights3 = np.array([-0.26, -0.27, 0.17, 0.87])\n",
    "\n",
    "# bias for 1st, 2nd and 3rd neuron\n",
    "bias1 = 2\n",
    "bias2 = 3\n",
    "bias3 = 0.5\n",
    "\n",
    "outputs = [\n",
    "# Neuron 1:\n",
    "np.dot(inputs, weights1) + bias1,\n",
    "\n",
    "# Neuron 2:\n",
    "np.dot(inputs, weights2) + bias2,\n",
    "\n",
    "# Neuron 3:\n",
    "np.dot(inputs, weights3) + bias3]\n",
    "\n",
    "print(f\"Outputs from layer = {outputs}\")\n",
    "\n",
    "for i, op in enumerate(outputs, 1):\n",
    "    out = f\"Output for Neuron {i} is $y_{i}$ = {op}\"\n",
    "    display(Latex(out))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now write bias in vector form and use that instead of bias1, bias2, bias3. Instead of writing bias at 3 places we write it in one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs from layer = [4.8   1.21  2.385]\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "Output for Neuron 1 is $y_1$ = 4.8"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Output for Neuron 2 is $y_2$ = 1.21"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Output for Neuron 3 is $y_3$ = 2.385"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# inputs\n",
    "inputs = np.array([1, 2, 3, 2.5])\n",
    "\n",
    "# weights for 1st neuron\n",
    "weights1 = np.array([0.2, 0.8, -0.5, 1])\n",
    "\n",
    "# weights for 2nd neuron\n",
    "weights2 = np.array([0.5, -0.91, 0.26, -0.5])\n",
    "\n",
    "# weights for 3rd neuron\n",
    "weights3 = np.array([-0.26, -0.27, 0.17, 0.87])\n",
    "\n",
    "# bias for 1st, 2nd and 3rd neuron\n",
    "biases = np.array([2, 3, 0.5])\n",
    "\n",
    "outputs_ = [\n",
    "# Neuron 1 dot product:\n",
    "np.dot(inputs, weights1),\n",
    "\n",
    "# Neuron 2 dot product:\n",
    "np.dot(inputs, weights2),\n",
    "\n",
    "# Neuron 3 dot product:\n",
    "np.dot(inputs, weights3)]\n",
    "\n",
    "outputs = outputs_ + biases\n",
    "\n",
    "print(f\"Outputs from layer = {outputs}\")\n",
    "\n",
    "for i, op in enumerate(outputs, 1):\n",
    "    out = f\"Output for Neuron {i} is $y_{i}$ = {op}\"\n",
    "    display(Latex(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this section onwards we assume that reader has knowledge of $\\textbf{Matrix Multiplication and Transpose of a Matrix}$. However shot explaination of Tranpose and demonstration is given below.\n",
    "- Transpose of a matrix is given by interchanging rows with columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 4],\n",
       "       [2, 5],\n",
       "       [3, 6]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_ = np.array([[1,2,3],\n",
    "                    [4,5,6],])\n",
    "\n",
    "# Tranpose of the matrix will be\n",
    "matrix_.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not want to write weights for each neuron in seperate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs from layer = [4.8   1.21  2.385]\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "Output for Neuron 1 is $y_1$ = 4.80"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Output for Neuron 2 is $y_2$ = 1.21"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Output for Neuron 3 is $y_3$ = 2.38"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# inputs\n",
    "inputs = np.array([1, 2, 3, 2.5])\n",
    "\n",
    "# weights for 1st, 2nd, 3rd neuron\n",
    "weights = np.array([[0.2, 0.8, -0.5, 1],\n",
    "                    [0.5, -0.91, 0.26, -0.5],\n",
    "                    [-0.26, -0.27, 0.17, 0.87]])\n",
    "\n",
    "# bias for 1st, 2nd and 3rd neuron\n",
    "biases = np.array([2, 3, 0.5])\n",
    "\n",
    "outputs = np.dot(inputs, weights.T) + biases\n",
    "\n",
    "print(f\"Outputs from layer = {outputs}\")\n",
    "\n",
    "for i, op in enumerate(outputs, 1):\n",
    "    out = f\"Output for Neuron {i} is $y_{i}$ = {op:.2f}\"\n",
    "    display(Latex(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until this point we have only seen one input vector to the neuron but there can be many input vectors which are given to neuron called batch of inputs. we will see what a batch of inputs is from given example all fundamentals remain unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs from layer for 3 inputs each containing 3 elements are:\n",
      "[[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# inputs\n",
    "inputs = np.array([[1, 2, 3, 2.5],\n",
    "                    [2.0, 5.0, -1.0, 2.0],\n",
    "                    [-1.5, 2.7, 3.3, -0.8]])\n",
    "\n",
    "# weights for 1st, 2nd, 3rd neuron\n",
    "weights = np.array([[0.2, 0.8, -0.5, 1],\n",
    "                    [0.5, -0.91, 0.26, -0.5],\n",
    "                    [-0.26, -0.27, 0.17, 0.87]])\n",
    "\n",
    "# bias for 1st, 2nd and 3rd neuron\n",
    "biases = np.array([2, 3, 0.5])\n",
    "\n",
    "outputs = np.dot(inputs, weights.T) + biases\n",
    "\n",
    "print(f\"Outputs from layer for 3 inputs each containing 3 elements are:\\n{outputs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After basic understanding of these concepts we are ready to give our code some touch of Pytorch. We will mimic the Linear class present in Pytorch which is used to create a layer of neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ouput of the layer :\n",
      "[[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n"
     ]
    }
   ],
   "source": [
    "class Linear:\n",
    "    def __init__(self):\n",
    "        self.weigths = np.array([[0.2, 0.8, -0.5, 1],\n",
    "                    [0.5, -0.91, 0.26, -0.5],\n",
    "                    [-0.26, -0.27, 0.17, 0.87]])\n",
    "        self.biases = np.array([2, 3, 0.5])\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return self.forward(inputs)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = np.dot(inputs, weigths.T) + self.biases\n",
    "        return outputs\n",
    "\n",
    "# inputs\n",
    "inputs = np.array([[1, 2, 3, 2.5],\n",
    "                    [2.0, 5.0, -1.0, 2.0],\n",
    "                    [-1.5, 2.7, 3.3, -0.8]])\n",
    "\n",
    "# A single layer if 3 neurons initialise                  \n",
    "single_layer_of_3_neurons = Linear()\n",
    "\n",
    "# feed forward the inputs to the neurons\n",
    "ouputs = single_layer_of_3_neurons.forward(inputs)\n",
    "\n",
    "#  or we can also write instead of above feed forward\n",
    "outputs = single_layer_of_3_neurons(inputs)\n",
    "\n",
    "# print the outputs\n",
    "print(f\"Ouput of the layer :\\n{outputs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually we dont set weigths and biases manually we either randomly give some initial values to weights and biases or use other sophesticated methods to initialise them for now we will use random values to initialise the weights and biases. However the results you will see below do not match with the results we got above because we are initializing the weights and biases with random values and each time you run it will cahange the results. (Note:- If you want to get same results then as this notebook we use seed method for reproducability.)\n",
    "- n_inputs means number of inputs (remember the difference between number of inputs and batch of inputs). We use this to initialise the weights beacuse number of weights = number of inputs.\n",
    "- n_neurons means number of neurons that one layer is going to have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ouput of the layer :\n",
      "[[ 2.8   -1.79   1.885]\n",
      " [ 6.9   -4.81  -0.3  ]\n",
      " [-0.59  -1.949 -0.474]]\n"
     ]
    }
   ],
   "source": [
    "# for getting same results as this use seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# define a linear class that will create a layer of neurons\n",
    "class Linear:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weigths = np.random.randn(n_neurons, n_inputs)\n",
    "        self.biases = np.zeros(n_neurons)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return self.forward(inputs)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = np.dot(np.array(inputs), weigths.T) + self.biases\n",
    "        return outputs\n",
    "\n",
    "    def __repr__(self):\n",
    "        n_n, n_i = self.weigths.shape \n",
    "        return f\"This is a Layer of neurons having {n_n} neurons and {n_i} inputs.\"\n",
    "\n",
    "# inputs\n",
    "inputs = np.array([[1, 2, 3, 2.5],\n",
    "                    [2.0, 5.0, -1.0, 2.0],\n",
    "                    [-1.5, 2.7, 3.3, -0.8]])\n",
    "\n",
    "# A single layer if 3 neurons initialise                  \n",
    "single_layer_of_3_neurons = Linear(4, 3)\n",
    "\n",
    "# feed forward the inputs to the neurons\n",
    "ouputs = single_layer_of_3_neurons.forward(inputs)\n",
    "\n",
    "#  or we can also write instead of above feed forward\n",
    "outputs = single_layer_of_3_neurons(inputs)\n",
    "\n",
    "# print the outputs\n",
    "print(f\"Ouput of the layer :\\n{outputs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example code of Layer in Pytorch:\n",
    "In pytorch the code for creating the Layer having 3 neurons and batch of input where each input has 4 elements is given as follows. \n",
    "We are doing same thing we have done above using Pytorch Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of the layer using Pytorch:\n",
      "[[ 2.3785372   0.16377497  1.4859807 ]\n",
      " [ 4.2447104   1.1837987  -0.95887226]\n",
      " [ 0.16251713 -0.53376347 -0.05115128]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# inputs\n",
    "inputs = np.array([[1, 2, 3, 2.5],\n",
    "                    [2.0, 5.0, -1.0, 2.0],\n",
    "                    [-1.5, 2.7, 3.3, -0.8]], dtype=np.float32)\n",
    "\n",
    "# Create a layer using pytroch\n",
    "layer = nn.Linear(in_features=4, out_features=3)\n",
    "\n",
    "# print the results\n",
    "print(f\"Output of the layer using Pytorch:\\n{layer(torch.tensor(inputs)).detach().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and Future Work:\n",
    "- We have implemented and understood what is layer or layer of neurons.\n",
    "- We have pytorchified our code so that it will mimic pytorch classes and functions that we are going to see in future.\n",
    "- We have seen inputs and batch of inputs.\n",
    "- We have seen matrix multiplication and trasnpose of matrix in action.\n",
    "- We have addressed the previous future work in this by making our code more modular and implementing a layer of neurons instead of single neuron.\n",
    "- In future we would like to see FCCNN $\\textit{i.e}$ many layers stacked on top of each other called a neural network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
