{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFNN (Feed Forward Neural Network is also called) or MLP (Multi Layer Perceptron) or FCNN (Fully Connected Neural Network).\n",
    "So what are Feed Forward Neural Networks?$\\newline$\n",
    "They are just layer stacked on top of each other in which the information flows in one direction from input layer to hidden layers then finally to output layer.$\\newline$\n",
    "Now that we know that it is just layers that are stacked so that information from one layer is passed to another layer. We will use the Linear class created in previous chapter to make FFNN.$\\newline$\n",
    "The example given below gives the demonstration of how we can create FFNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# for getting same results as this use seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# define a linear class that will create a layer of neurons\n",
    "class Linear:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weigths = np.random.randn(n_neurons, n_inputs)\n",
    "        self.biases = np.zeros(n_neurons)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return self.forward(inputs)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = np.dot(np.array(inputs), self.weigths.T) + self.biases\n",
    "        return outputs\n",
    "\n",
    "    def __repr__(self):\n",
    "        n_n, n_i = self.weigths.shape \n",
    "        return f\"This is a Layer of neurons having {n_n} neurons and {n_i} inputs.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below section we have defined four layers in which 3 layers are hidden and layer 4 is output layer which will produce output for us.\n",
    "- We have each input of size 4 so our first layer has number of inputs four and it contains 5 neurons which will produce 5 output (single output for each cell).\n",
    "- No the layer1 has produced an output of size 5 becuase it had five neurons now the output of the first layer will become input to the second layer, hence the number of inputs for the second layer are 5 and we have 16 neurons in the second layer which will produce 16 outputs or a vector of size 16 that will become input tp the next layer.\n",
    "- Layer three has 16 inputs from the previous layer and has 32 neurons which will produce 32 size vector as output and the 32 size vector will be given as input to the output layer.\n",
    "- The output layer recieves the 32 inputs from the layer3 and has 2 neurons which will produce 2 outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Input layer inputs\n",
    "inputs = np.array([[1, 2, 3, 2.5],\n",
    "                    [2.0, 5.0, -1.0, 2.0],\n",
    "                    [-1.5, 2.7, 3.3, -0.8]])\n",
    "\n",
    "# Layer 1\n",
    "layer1 = Linear(n_inputs=4, n_neurons=5)\n",
    "\n",
    "# layer 2\n",
    "layer2 = Linear(n_inputs=5, n_neurons=16)\n",
    "\n",
    "# layer 3 \n",
    "layer3 = Linear(n_inputs=16, n_neurons=32)\n",
    "\n",
    "# layer 4 output layer\n",
    "layer4 = Linear(n_inputs=32, n_neurons=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would like to feed the information in our layers starting from layer1 then to layer2 then after that to layer3 and finally to layer4 called output layer.\n",
    "- As you can see that we can see only input data and the output from the layer 4 output layer.\n",
    "- All of the other layers where we do not directly interact with the data our output of the layer are called hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output for three batch inputs\n",
      "[[ 132.81398873   47.94457735]\n",
      " [  34.19256703   88.70064425]\n",
      " [-324.12107519 -273.03926316]]\n"
     ]
    }
   ],
   "source": [
    "output_of_layer1 = layer1.forward(inputs)\n",
    "output_of_layer2 = layer2.forward(output_of_layer1)\n",
    "output_of_layer3 = layer3.forward(output_of_layer2)\n",
    "output_of_layer4 = layer4.forward(output_of_layer3)\n",
    "print(f\"Output for three batch inputs\\n{output_of_layer4}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and Future Work:\n",
    "- We have successfully implemeneted the Feed Forward Neural Network from scratch.\n",
    "- In future we would like to implement activation functions used in the neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
